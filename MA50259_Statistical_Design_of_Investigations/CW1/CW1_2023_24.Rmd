---
title: 'MA50259: Statistical Design of Investigations'
author: "Coursework 1 (2024)"
candidate number: "239390631"
output:
  pdf_document: default
  html_document:
    df_print: paged
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(Matrix)
```

\underline{Disclaimer}:

AI software (RStudio built-in Co-Pilot and ChatGPT) are used in this coursework for code, RMarkdown formatting, and explanation suggestions, debugging purposes.

# Part 1: Baking Powder Experiment

In an experiment to study the effect of the amount of baking powder in a
biscuit dough upon the rise heights (measured in centimetre) of the
biscuits, four levels of baking powder were tested and four replicate
biscuits were made with each level in a random order. The results are
shown in the table below (tsp stands for teaspoon)

```{=tex}
\begin{center}
%\captionof{table}{Comparison of performance of three different methods for $\lambda=8$, $n=1000$, $K=3$ and balanced community size with varying OIR\label{perftab1result}}  % title name of the table
%\label{estimresult}
\begin{tabular}{l c c c}  % creating 10 columns
\hline                       % inserting double-line
 .25 tsp & 0.5 tsp & .75 tsp & 1 tsp\\
\hline
11.4 & 27.8 & 47.6 & 61.6\\
11.0 & 29.2 & 47.0 & 62.4\\
11.3 & 26.8 & 47.3 & 63.0\\
 9.5 & 26.0 & 45.5 & 63.9
\end{tabular}
\end{center}
```
1.  What is the experimental unit and which type of experimental design
    is this?

\hrulefill

\underline{Answer:}

\textbf{Definition} of an \textit{experimental unit}: The item under
study upon which something is changed. This could be things, human
subjects, or just a point in time.

The \textit{experimental unit} in this experiment is each individual
biscuit.

\textbf{Definition} of a \textit{experimental design}: A collection of
experiments or runs that is planned in advance of the actual execution.
The particular runs selected in an experimental design will depend upon
the purpose of the design.

This type of experimental design is known as completely randomised
design (CRD).

\hrulefill

2.  Read-in the data in the table above in R as a \texttt{data.frame} in
    such a way that it can be used by the \texttt{lm} function without
    any modification, that is, your data frame should have 2 columns and
    16 rows. The variables in the dataframe should be called
    \texttt{riseht} and \texttt{type}. The data frame should be called
    \texttt{biscuits}

```{r}
options(width = 50)
biscuits <- data.frame(riseht=c(11.4,11.0,11.3,9.5,27.8,29.2,26.8,26.0,47.6,47.0
                                ,47.3,45.5,61.6,62.4,63.0,63.9),
                       type=rep(c(0.25,0.5,0.75,1),each=4))
biscuits$type <- factor(biscuits$type)
```

3.  Construct in R, the design matrix $\boldsymbol{X}$ corresponding to
    the model: $$y_{ij}=\mu+\tau_j+\epsilon_{ij}$$ where
    $\tau_{0.25}, \tau_{0.50}$, $\tau_{0.75}$ and $\tau_{1.0}$ are the
    effects of the levels of the baking powder. All
    $\epsilon_{ij}\sim N(0,\sigma^2)$ and are mutually independent.

```{r}
y <- biscuits$riseht
t <- length(unique(factor(biscuits$type))) # number of treatments
r <- nrow(biscuits)/t # number of replicates per treatment
n <- nrow(biscuits) # total number of experimental units
levels <- unique(factor(biscuits$type)) # levels of the baking powder
fact <- gl(t,r,labels=levels) # factor variable
Z <- model.matrix(~fact-1) # matrix Z as the means model of a CRD
X <- cbind(1,Z) # design matrix X as the treatment effects model of a CRD

# naming the columns
colnames(X) <- c("reference", "0.25 tsp", "0.50 tsp", "0.75 tsp", "1.00 tsp")

# Display the design matrix X
X
```

4.  How many unknown parameters are in the model?

\hrulefill

\underline{Answer:}

5 unknown parameters:

i.  One reference rise height of the biscuit when there is no treatment
    $\mu$

ii. Four treatment effects $\tau_{i}$ for $i=1,2,3,4$

\hrulefill

5.  Find the rank of the design matrix $\boldsymbol{X}$. You should
    justify your answer.

```{r}
qr(X)$rank
```

\hrulefill

\underline{Answer:}

The rank of the design matrix $\boldsymbol{X}$ is 4. This is because the
design matrix $\boldsymbol{X}$ has 5 columns and the rank of a matrix is
the maximum number of linearly independent column vectors in the matrix.
The first column of $\boldsymbol{X}$ is a column of ones, and thus the
remaining 4 columns are dependent on the first column but not to one
another. Therefore, the rank of $\boldsymbol{X}$ is 4 as shown in the QR
decomposition of $\boldsymbol{X}$ above.

\hrulefill

6.  Perform the analysis of variance to test the hypothesis of no
    treatment effect. You should do the computations using the theory
    given in the lectures and not simply use the command \texttt{aov}.

```{r}
# The ANOVA table is computed using the following steps:
# Calculate grand mean
grand_mean <- mean(y)

# Calculate the total sum of squares (SSTotal)
SSTotal <- sum((y - grand_mean)^2)

# Calculate the treatment sum of squares (SSTreatment)
means <- tapply(y, biscuits$type, mean)
SSTreatment <- sum(r*means^2) - n*grand_mean^2

# Calculate the error sum of squares (SSError)
SSError <- SSTotal - SSTreatment

# Alternative code for SSError
# t(matrix(y,ncol=1))%*%(diag(n)-(1/n)*rep(1,n)%*%t(rep(1,n)))%*%matrix(y,ncol= 1)

# Calculate the degrees of freedom for the treatment (dfTreatment)
dfTreatment <- t - 1

# Calculate the degrees of freedom for the error (dfError)
dfError <- n - t

# Calculate the mean square for the treatment (MSTreatment)
MSTreatment <- SSTreatment/dfTreatment

# Calculate the mean square for the error (MSError)
MSError <- SSError/dfError

# Calculate the F-statistic
F_stat <- MSTreatment/MSError

# Calculate the p-value
p_value <- 1 - pf(F_stat,dfTreatment,dfError)

kable(
  data.frame(
    Source = c("Treatment", "Error", "Total"),
    `Sum of Squares` = c(SSTreatment, SSError, SSTotal),
    `Degrees of Freedom` = c(dfTreatment, dfError, n - 1),
    `Mean Square` = c(round(MSTreatment, 4), round(MSError, 4), ""),
    `F-statistic` = c(round(F_stat, 4), "", ""),
    `p-value` = c(sprintf("%.2e",p_value), "", "")
  ),
  align = "c"
)

```

\hrulefill

\underline{Answer:}

The hypothesis test is as follows:

The null hypothesis, $H_0$: $\tau_1 = \tau_2 = \tau_3 = \tau_4$.

The alternative hypothesis, $H_a$: at least two of the $\tau$s differs.

Let the significance level be $\alpha = 0.05$. The null hypothesis is
that there is no treatment effect, that is,
$\tau_1 = \tau_2 = \tau_3 = \tau_4$. The alternative hypothesis is that
at least one of the $\tau$s are not equal. Given that we obtained a
p-value of $3.33 \times 10^-16$, which is less than the significance
level of 0.05 (*5% is commonly used in a typical hypothesis test*), we
reject the null hypothesis and conclude that there is a treatment
effect.

\hrulefill

7.  Formulate a contrast to test the hypothesis that increase in rise
    height is a linear function of the increase in baking powder in the
    dough, and test this hypothesis.

```{r}
# Contrast Reference: https://online.stat.psu.edu/stat555/node/73/

# Formulate the contrast
# Since we are testing whether the increase in rise height is a linear function of the
# increase in baking powder in the dough, we can use the contrast:
linear_contrast_c <- c(0, -3, -1, 1, 3)
ginverse <- rbind(0, cbind(0, solve(t(Z) %*% Z)))
beta <- ginverse %*% t(X) %*% y

# Calculate the contrast estimate
contrast_estimate <- linear_contrast_c %*% beta

# Calculate the standard error of the contrast estimate
# The standard error of the contrast estimate is calculated using the formula:
# SE = sqrt(MSerror * sum(c^2)/t)
# Refer: https://websites.umich.edu/~gonzo/coursenotes/file3.pdf page 3-3 
SE_contrast_estimate <- sqrt(MSError * sum(linear_contrast_c^2)/t)

# Calculate the t-statistic
t_stat <- contrast_estimate / SE_contrast_estimate

# Calculate the p-value in a two-tailed test
# Refer: https://www.geeksforgeeks.org/how-to-calculate-the-p-value-of-a-t-score-in-r/
p_value_contrast <- 2 * pt(-abs(t_stat), dfError)


kable(
  data.frame(
    Contrast = c("Contrast Test"),
    `Contrast Estimate` = round(contrast_estimate, 2),
    `Contrast Standard Error` = round(SE_contrast_estimate, 2),
    `t-Statistic` = round(t_stat, 2),
    `p-Value` = sprintf("%.2e", p_value_contrast)
  ),
  align = "c"
)
```

\hrulefill

\underline{Answer:}

A contrast is a linear combination
$\mathbf{c}^T\beta = c_0\mu + \sum_{i=1}^{t}c_i\tau_i$ of the treatment
means , where $\sum_{i=0}^{t}c_i = 0$.

A contrast allows us to test the hypothesis that increase in rise height
is a linear function of the increase in baking powder in the dough.

Let $c_0 = 0$ as we are only interested to check for presence of a
linear trend due to varying the amount of baking powder used.

Since we are testing whether the increase in rise height is a linear
function of the increase in baking powder in the dough, we can use the
contrast: $$c = (0, -3, -1, 1, 3)$$ which is a classical orthogonal
contrast coefficients for testing the linear trend in the treatment
means. This also fulfils the requirement that the sum of the contrast
weights is equal to zero $\sum{c} = 0 - 3 - 1 + 1 + 3 = 0$.

The contrast weights are chosen such that the first treatment level is
weighted by -3, the second treatment level is weighted by -1, the third
treatment level is weighted by 1, and the fourth treatment level is
weighted by 3. Doing so allows the $\tau_2$ and $\tau_3$ to serve as a
pivot point for the linear trend, while multiplying $\tau_1$ by -3
allows us to "pull" the contrast value down, and multiplying $\tau_4$ by
3 allows us to "push" the contrast value up. Thus allows symmetrical
distribution of the contrast weights around the pivot point, making it
suitable to check a simple linear trend.

$~$ $~$

\underline{Setting up our hypothesis test:}

Let:

The null hypothesis, $H_0$: $\tau_1 = \tau_2 = \tau_3 = \tau_4$.

The alternative hypothesis, $H_a$: at least two of the $\tau$s differs.

$~$ $~$

\underline{Calculating beta:}

From the equation:

$$\boldsymbol{X^TX\beta}=\boldsymbol{X^Ty}$$

we can rewrite the equation to find $\tilde{\boldsymbol{\beta}}$ as:

$$\tilde{\boldsymbol{\beta}}=(\boldsymbol{X^TX})^{-} \boldsymbol{X^Ty}$$ where $(\boldsymbol{X^TX})^{-}$ is the generalized inverse of $\boldsymbol{X^TX}$.

A generalized inverse of a square matrix $\boldsymbol{A}$ is another square matrix $\boldsymbol{A^-}$ satisfying $$\boldsymbol{AA^-A=A}$$

The generalized inverse of a non-full rank matrix is used to estimate the variance of the experimental error using the technique $$(\boldsymbol{X^TX})^-=
\left(
\begin{array}{cc}
0 & 0\\
0 & (\boldsymbol{Z^TZ})^{-1} \\
\end{array}
\right)
$$

where $\boldsymbol{X}$ is the design matrix and $\boldsymbol{Z}$ is the matrix of means.


$~$ $~$

```{r}
kable(means, col.names = c("Treatment Level", "Means Within Individual Treatment Levels"), align = "c")
```
The contrast estimates to 175.18 using the formula:

$c^T\hat{\beta} = 0 + c^T\hat{\tau_i} = \text{contrast weight} \times \text{mean within individual treatment levels} = (-3 \times 10.800) + (-1 \times 27.450) + (1 \times 46.850) + (3 \times 62.725) = 175.18$

$~$

Next, we calculate the standard error of the contrast using the formula:

$\text{standard error (contrast)} = \sqrt{MSE \times \frac{\sum_{i=1}^{t}c_i^2}{\text{no. of treatment levels checked in this contrast}}} = \sqrt{1.124 \times \frac{(-3)^2 + (-1)^2 + (1)^2 + (3)^2}{4}} = 2.37$

where

$MSE = \text{mean square error}$

$c_i = \text{contrast weight}$

$t = \text{number of treatments}$

$~$ $~$

The t-statistic is calculated using the formula:

$t = \frac{\text{contrast estimate}}{\text{standard error (contrast)}} = \frac{175.18}{2.37} = 73.89$

$~$ $~$

The p-value is calculated using a t-score of 73.89 and 12 degrees of
freedom (n-t = 16-4 = 12). We obtain a p-value of $2.51 \times 10^-17$,
which is less than the significance level of 0.05 (*5% is commonly used
in a typical hypothesis test*). Therefore, we reject the null hypothesis
and conclude that there is a linear trend in the treatment means given
that the p-value is less than 0.05 ($2.51 \times 10^-17 < 0.05$).

\hrulefill

8.  Estimate the variance $\sigma^2$ of the experimental error.

```{r}
# Estimate the variance of the experimental error
# The variance of the experimental error is estimated using the formula:
# \hat{\sigma}^2 = SSE / (n - t)

# Formulate the ginverse for non-full rank treatment model
SSE_matrix_method <- t(y) %*% (diag(n) - X %*% ginverse %*% t(X)) %*% y
variance_of_experimental_error <- round(SSE_matrix_method / (n - t), 4)
variance_of_experimental_error
```

\hrulefill

\underline{Answer:}

The variance of the experimental error is estimated to be 1.124 using the formula $\hat{\sigma}^2 = \frac{SSE}{n - t}$.

Sum of Square Error (SSE) is calculated using the formula $$\boldsymbol{y^T(I-X(X^TX)^-X^T)y}$$

where:

- $\boldsymbol{y}$ is the response vector

- $\boldsymbol{I}$ is the identity matrix

- $\boldsymbol{n}$ is the total number of experimental units

- $\boldsymbol{t}$ is the number of treatments.

\hrulefill


9.  Discuss whether the assumptions for the considered linear model are
    justified.

\hrulefill

\underline{Answer:}

The assumptions for the considered linear model are:

1. There is an additive effect of the treatment levels on the means, e.g. $\mu_i = \mu + \tau_i$.

The assumption is justified as based on our contrast test, we have found that there is a linear trend in the treatment means. This means that the increase in rise height is a linear function of the increase in baking powder in the dough.

2. If the units are homogeneous, the probability distribution of the response $y_{ij}$ or the experimental error $\epsilon_{ij}$, under the same treatment level, is the same.

3. The probability distribution of the response $y_{ij}$ or the experimental error $\epsilon_{ij}$, is Gaussian.

The two assumptions are justified as the experimental error $\epsilon_{ij}$ is assumed to be normally distributed with a mean of 0 and a constant variance $\sigma^2I$. This is supported by the fact that the variance of the experimental error is estimated to be 1.124 which is less than the variance due to the treatment effects of $\frac{SSTreatment}{dfTreatment} = \frac{6145.732}{3} = 2048.577$. This means that the experimental error is not large enough to affect the validity of the model.

```{r}
# variance due to the treatment effects
SSTreatment / dfTreatment

```


\hrulefill

10. If the dough were made in batches and the four replicate biscuit
    rise heights in each column (shown in the table above) were all from
    the same batch, would your answer to (a) be different? How could the
    data be analysed if this were the case?

\hrulefill

\underline{Answer:}

It would change the nature of the experiment as we lost the advantages gained due to randomisation. The assumption of independence of the errors $\epsilon_{ij}$ would be violated. This is because the errors $\epsilon_{ij}$ would not be independent of one another. In this case, the data could be analysed using a randomised complete block design where the blocks would be the batches of dough and the treatments would be the levels of the baking powder. 

\hrulefill


# Part 2: Free fall of Papers of Different Dimension

In this part of the coursework you will design a factorial experiment,
collect the data and then analyse it. You will carry out this experiment
to identify how different design factors influence the free fall time of
a piece of paper.

**Experimental Units**

In this experiment each experimental unit will correspond to a single
piece of paper. Replicates will mean you will have to use as many papers
of different dimension as needed.

**Instructions**

In this experiment you will need to drop many pieces of paper from a
certain height. Please follow the following instructions:

-   Use white printer paper (if needed you can use the university
    printer papers).

-   Label your papers according to the factor variables (described
    below) and the replicate number.

-   Perform the experiment in a large open space, mostly isolated from
    wind.

-   Always allow the papers to fall approximately from the same height,
    straight towards the floor.

-   You can do some practice before starting the main experiment, but I
    recommend to use different papers for this. The practice papers can
    be used more than once.

-   Do not do all the experiment in one go. Take a few breaks to make
    sure your arm does not get tired and always use the same arm for the
    experiment.

-   Recycle all the paper after finishing the experiment.

**Response**

Time in seconds (time to be recorded to the nearest whole second) of the
free fall of the paper. To measure the free fall time, follow the
following instructions:

-   Locate a position from where you would drop the piece of paper. You
    can mark that with your bag/other item. Stand there and drop the
    piece of paper from a certain height. Use your mobile/ a stopwatch
    to record the free fall time of the paper.

-   Record the times in seconds (time to be recorded to the nearest
    whole second) in a spreadsheet making reference to each level of the
    factor.

-   If anything goes wrong, for example if the paper touches your body
    before falling down, repeat that particular run with a different
    (pristine) paper.

-   Repeat the experiment by dropping the pieces of paper from
    (approximately) the same height every time.

**Factor variables**

-   Factor 1 (length of the paper): (2 levels) 5 cm, 6 cm. You can
    measure the length using a ruler.

-   Factor 2 (Width of the paper): (2 levels) 5.5 cm, 6.5 cm. You can
    measure the width using a ruler.

**Randomization**

Remember to assign the factor level combinations to the experimental
units (the piece of paper) completely at random. You can do this in R
using the \texttt{sample} function. For example, for a balanced design
with $r=3$ replicates, you can assign the level combinations to a total
of 12 papers using the following command

```{r}
f<-rep(c("5,5.5","6,5.5","5,6.5","6,6.5"),each=3)
sample(f,12)
```

The experiment will be balanced in the sense that each factor level
combination will have the same number of replicates $r$ but you will
have to determine the number of replicates. For this, consider the model
with interactions:

$$y_{ijk}=\mu+\tau_i+\alpha_j +\gamma_{ij}+\epsilon_{ijk}$$

where $\tau_{3.5}, \tau_{4.5}$ are the effects of the two different
lengths of the papers, $\alpha_{3}, \alpha_{4}$ are the effects of the
two different widths of the papers, $\gamma_{ij}$ are the effects of the
interactions. All $\epsilon_{ijk}\sim N(0,\sigma^2)$ and are mutually
independent.

Before running the main experiment, you will need to perform a simple
pilot experiment in order to estimate the variance parameter $\sigma^2$.
You should perform $n_{pilot}=10$ runs with 10 different papers of
length 5 cm and width 5.5 cm.

Specifically of length 5 cm and width 5.5 cm respectively. Denote by
$t_1,\ldots,t_{10}$ the observed times in seconds. You should estimate
the variance in the usual way, that is,
$$\widehat{\sigma}^2=\frac{1}{n_{pilot}-1}\sum_{i=1}^{10}(t_i-\bar{t})^2$$

a)  Report your 10 observations from the pilot experiment as well as
    your estimated value of $\sigma^2$.

```{r}
# Pilot experiment
pilot_raw <- c(3.28, 3.52, 3.56, 3.54, 3.66, 3.62, 2.98, 3.10, 3.28, 2.98)

# Round to nearest whole second
pilot <- round(pilot_raw)

kable(
  data.frame(
    `Number of Observations` = 1:10,
    `Free Fall Time` = pilot_raw,
    `Free Fall Time Rounded to Nearest Second` = pilot
  ),
  align = "c"
)

# Estimating the variance of the experimental error using the given formula
variance_of_experimental_error_pilot <- round(sum((pilot - mean(pilot))^2) / (length(pilot) - 1), 4)
variance_of_experimental_error_pilot
```

b)  Denote $\Delta_{5}:=\mu_{5,5.5}-\mu_{5,6.5}$ and
    $\Delta_{6}:=\mu_{6,5.5}-\mu_{6,6.5}$ where $\mu_{ij}$ is the mean
    response for length $i\in\{5,6\}$ and width $j \in \{5.5, 6.5\}$.
    State the null and the alternative hypotheses for a two-sided test
    of $\Delta_{5} = \Delta_{6}$. Let
    $\Delta = |\Delta_{5} - \Delta_{6}|$. We would like to detect an
    absolute difference $\Delta=1$ with high power. Determine the number
    of replicates $r$ necessary to achieve at least 90% power using a
    significance level $\alpha=0.05$.

```{r}
library(daewr)
# Power calculation
rmin <- 2
rmax <- 10
alpha <- 0.05
delta <- 1
nlev <- c(2,2)
nreps <- c(rmin:rmax)
power <- Fpower2(alpha, nlev, nreps, delta, sqrt(variance_of_experimental_error_pilot))
kable(power, align = "c")
```

\hrulefill

\underline{Answer:}

The null hypothesis, $H_0$: $\Delta_{5} = \Delta_{6}$.

The alternative hypothesis, $H_a$: $\Delta_{5} \neq \Delta_{6}$.


We would like to detect an absolute difference $\Delta=1$ with high power. The number of replicates $r$ necessary to achieve at least 90% power using a significance level $\alpha=0.05$ is $nrep = 4$.

\hrulefill

```{r}
# Generating the data
set.seed(37) # Set seed for reproducibility
f<-rep(c("5,5.5","6,5.5","5,6.5","6,6.5"),each=4)
sample(f,16)

# Inputting the collect data into a dataframe (Exclude the non-rounded observed values)
df <- data.frame(
    `Length` = c(6, 6, 6, 5, 5, 6, 5, 5, 5, 5, 6, 6, 5, 6, 5, 6),
    `Width` = c(5.5, 6.5, 5.5, 5.5, 5.5, 6.5, 5.5, 6.5, 6.5, 6.5, 5.5, 6.5, 6.5, 5.5, 5.5, 6.5),
    `Fall_Time` = c(3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 4, 4) 
  )

# Displaying the collected data in a table
kable(
  data.frame(
    `Number of Observations` = 1:16,
    `Length` = c(6, 6, 6, 5, 5, 6, 5, 5, 5, 5, 6, 6, 5, 6, 5, 6),
    `Width` = c(5.5, 6.5, 5.5, 5.5, 5.5, 6.5, 5.5, 6.5, 6.5, 6.5, 5.5, 6.5, 6.5, 5.5, 5.5, 6.5),
    `Observed_Value` = c(3.35, 3.45, 3.57, 3.58, 3.45, 3.3, 3.2, 3.16, 2.85, 3.07, 3.4, 3.72, 3.2, 3.7, 3.68, 3.98),
    `Observed_Value_Rounded` = c(3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 4, 4) 
  ),
  align = "c"
)
```

c)  Use ANOVA and your collected data to test if length of paper has a
    significant effect. Clearly state the hypotheses you are testing.
    Repeat the test but now consider width instead of length of paper.

\hrulefill

\underline{Answer:}

For a two-factor factorial:

The means model:

$$y_{ijk} = \mu_{ij} + \epsilon_{ijk}$$

where:

- $i$ represents the level of the first factor
- $j$ represents the level of the second factor
- $k$ represents the replicate number
- $\mu_{ij}$ represents the expected response in the ($i, j$)th cell

and its corresponding effects model:
#TODO: Retype this
$$y_{ijk} = \mu + \alpha_i + \beta_j + \gamma_{ij} + \epsilon_{ijk}$$

where:

- $\alpha_i$ (length of paper) and $\beta_j$ (width of paper) are the main treatment effects.
- $\gamma_{ij}$ is the interaction effect between the cell mean, $\mu_{ij}$ and $\mu + \alpha_i + \beta_j$.
- $\epsilon_{ijk}$ is the experimental error such that $E(\epsilon_{ijk}) = 0$ and $\epsilon ~ MVN(0, \sigma^2I)$.

```{r}
# Creating the design matrix X
# Define factor variables
# length_of_paper <- df %>% mutate(length = as.factor(length))
# width_of_paper <- factor(c(5.5, 6.5))
# 
# # Create interaction
# inter <- interaction(length_of_paper, width_of_paper, sep = ",")
# 
# # Create the design matrix
# X1 <- model.matrix(~length_of_paper - 1, df)
# X2 <- model.matrix(~width_of_paper - 1, df)
# X3 <- model.matrix(~inter - 1, df)
# 
# X <- rbind(X1, X2, X3)
# colnames(X)[1] <- "(intercept)"
# X

# Alternative method
length <- factor(df$Length)
width <- factor(df$Width)

paper_model <- as.formula("~ length * width")
X_paper <- model.matrix(paper_model)

time <- c(3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 4, 4)
factor_combination <- data.frame(
  length = c(6, 6, 6, 5, 5, 6, 5, 5, 5, 5, 6, 6, 5, 6, 5, 6),
  width = c(5.5, 6.5, 5.5, 5.5, 5.5, 6.5, 5.5, 6.5, 6.5, 6.5, 5.5, 6.5, 6.5, 5.5, 5.5, 6.5)
)
exp_results <- data.frame(time, factor_combination)

exp_results$length <- factor(exp_results$length)
exp_results$width <- factor(exp_results$width)

exp_model <- aov(time ~ length * width, data = exp_results)

test_results <- anova(exp_model)
test_results
```

\hrulefill

\underline{Answer:}

The hypothesis test for the length of paper is as follows:

The null hypothesis, $H_0$: $\tau_5 = \tau_6$. The alternative hypothesis, $H_a$: $\tau_5 \neq \tau_6$.

The hypothesis test for the width of paper is as follows:

The null hypothesis, $H_0$: $\alpha_{5.5} = \alpha_{6.5}$. The alternative hypothesis, $H_a$: $\alpha_{5.5} \neq \alpha_{6.5}$.

The p-value for the standalone effect of the length of the paper $\tau_i$ is $0.337$ which is greater than the significance level of $0.05$. Therefore, we fail to reject the null hypothesis and conclude that the length of the paper does not have a significant effect on the free fall time of the paper.

The p-value for the standalone effect of the width of the paper $\alpha_j$ is $0.337$ which is greater than the significance level of $0.05$. Therefore, we fail to reject the null hypothesis and conclude that the width of the paper does not have a significant effect on the free fall time of the paper.

\hrule

d)  Use the previous ANOVA table to comment on if the interaction effect
    is significant or not. Clearly state the hypotheses you are testing
    to check if the interaction effect is significant or not. Also,
    comment on the same using an appropriate plot. Mention any lurking
    variables one needs to be aware of.

\hrulefill

```{r}
# Interaction plot
interaction.plot(exp_results$length
                , exp_results$width
                , exp_results$time
                , xlab = "Length of Paper"
                , ylab = "Free Fall Time (seconds)"
                , trace.label = "Width of Paper"
                , legend = TRUE
                , col = c("red", "blue")
                , lwd = 2
                # , type = "b"
                , main = "Interaction Plot of Length and Width of Paper"
                 )
```

\underline{Answer:}

The hypothesis test for the interaction effect is as follows:

The null hypothesis, $H_0$: $\gamma_{ij} = 0$. The alternative hypothesis, $H_a$: $\gamma_{ij} \neq 0$.

The p-value for the interaction effect $\gamma_{ij}$ is $0.337$ which is greater than the significance level of $0.05$. Therefore, we fail to reject the null hypothesis and conclude that the interaction effect is not significant.


```{r}